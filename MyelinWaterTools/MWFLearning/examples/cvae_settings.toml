dir     = "."
prec    = 64
gpu     = false
save    = true
timeout = 15.0 # Training timeout (hours)

[data]
val_data    = ""
test_data   = "/project/st-arausch-1/jcd1994/ismrm2020/experiments/Spring-2020/permeability-training-1/test"
train_data  = "/project/st-arausch-1/jcd1994/ismrm2020/experiments/Spring-2020/permeability-training-1/train"
val_batch   = "auto" # Auto treats entire validation set as one batch
test_batch  = "auto" # Auto treats entire test set as one batch
train_batch = 1024 # Batch size for training
[data.info]
nfeatures   = "auto" # Height of input data
nchannels   = "auto" # Number of input data channels
nlabels     = "auto" # Number of output labels
labmean     = "auto" # Label means
labwidth    = "auto" # Label distribution widths
labnames    = ["cosd(alpha)", "gratio", "mwf", "T2mw/TE", "T2iew/TE", "log(TE*K)", "iwf", "ewf", "iewf", "T2iw/TE", "T2ew/TE", "T1mw/TE", "T1iw/TE", "T1ew/TE", "T1iew/TE"]
labinfer    = ["cosd(alpha)", "gratio", "mwf", "T2mw/TE", "T2iew/TE", "log(TE*K)"]
labweights  = [1.0, 1.0,   1.0,   1.0, 1.0, 1.0] # Weights for loss function
labscale    = [1.0, 100.0, 100.0, 1.0, 1.0, 1.0] # scale labels before plotting
labunits    = ["cosd(Â°)", "%", "%", "ms/ms", "ms/ms", "log(um)"] # label units, after scaling
[data.filter]
labnames    = [] #["nTE", "K" ]
lower       = [] #[ 32.0, 0.00]
upper       = [] #[ 64.0, 1.00]
[data.preprocess]
shuffle     = true
SNR         = [0.0] # Gaussian noise on complex signal (0 == no noise)
chunk       = 32 # Chunk of signal to keep
normalize   = "unitsum" # Normalize input signals (unitsum == signal sums to 1)
[data.preprocess.magnitude]
apply       = true
[data.postprocess]
SNR         = 40.0 # Rician noise on magnitude signal (0 == no noise)

[model]
loss      = "l2"
acc       = "rmse"
# [model.load]
# path    = "/home/jdoucette/Documents/code/BlochTorreyResults/Experiments/MyelinWaterLearning/ismrm2020/pretrained-dense-model-with-perm/2019-11-01-T-16-12-14-111.acc=rmse_loss=l2_DenseLIGOCVAE_Ndense1=128_Ndense2=128_Ndense3=128_Ndense4=128_Ndense5=128_Ndense6=128_Xout=6_Zdim=20_act=leakyrelu.model-checkpoint.bson"
[model.DenseLIGOCVAE]
Xout      = 6 # Number of learned labels
Nh        = 1 # Number of inner hidden dense layers
Dh        = 128 # Dimension of inner hidden dense layers
Zdim      = 8 # Latent variable dimension
act       = "relu"
# [model.ConvLIGOCVAE]
# Xout      = 6  # Number of learned labels
# Zdim      = 15 # Latent variable dimension
# Nfeat     = 8  # Number of convolutional channels
# Ndown     = 1  # Optional striding for downsampling
# act       = "relu"
# [model.RDNLIGOCVAE]
# Xout      = 6  # Number of learned labels
# Zdim      = 20 # Latent variable dimension
# Nrdn      = 4  # Number of RDN + downsampling blocks
# Ncat      = 2  # Number of concat blocks within RDN
# Nfeat     = 16 # Number of convolutional channels + RDN growth rate
# act       = "relu"

[optimizer]
epochs   = 1_000_000
lrrate   = 5000
lrdrop   = 3.1623
lrbounds = [1e-5, 0.1]
[optimizer.ADAM]
lr       = 3.1623e-4
beta     = [0.9, 0.999]
# decay   = 1e-5
# [optimizer.SGD]
# lr      = 1e-5
# rho     = 0.9
# decay   = 1e-5
