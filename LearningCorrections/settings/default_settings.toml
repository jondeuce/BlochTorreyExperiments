[data]
out    = "./output/hyb-tmp"
ntrain = 102_400
ntest  = 10_240
nval   = 10_240

[train]
timeout     = 1e9 #TODO
epochs      = 999_999
batchsize   = 1024 #2048 #3072
nbatches    = 10 # Number of batches sampled per epoch
kernelrate  = 10
kernelsteps = 10
GANrate     = 10 # Rate that genatr/discrim is trained using GAN losses
Dsteps      = 10 # Number of discrim training steps per genatr step

[eval]
ninfer      = 128 #TODO Number of MLE parameter inferences
nperms      = 128 # Number of permutations for c_alpha calculation + perm plot
inferperiod = 300.0 # TODO
saveperiod  = 300.0 #TODO
showrate    = 1 #TODO

[opt]
lrdrop   = 1.0 #10.0 3.1623 #1.7783
lrthresh = 1e-5
lrrate   = 1000
[opt.k]
loss = "tstatistic" #"MMD"
lr = 1e-2
[opt.mmd]
lr = 1e-4 #3.1623e-4 #1.0e-5 #TODO
[opt.G]
lr = 1e-4 #3.1623e-4 #1.0e-5 #TODO
[opt.D]
lr = 1e-4 #3.1623e-4 #1.0e-5 #TODO

[kernel]
nbandwidth = 4 #TODO
#bwbounds  = [-10.0, 4.0] # bounds for kernel bandwidths (logsigma)
bwbounds   = [-8.0, 4.0] # toy problem bounds for kernel bandwidths (logsigma)

[genatr]
hdim        = 128
nhidden     = 2
#maxcorr    = 0.005 # normalized signals
#noisebounds= [-10.0, -4.0] # normalized signals
#maxcorr    = 0.025 # unnormalized signals (but scaled down by 1e6)
#noisebounds= [-6.0, -3.0] # unnormalized signals (but scaled down by 1e6)
maxcorr     = 0.1 # toy signals
noisebounds = [-8.0, -2.0] # toy signals

[discrim]
hdim    = 128
nhidden = 2
