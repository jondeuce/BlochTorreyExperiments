[data]
out    = "./output/ignite-tmp"
ntrain = 102_400
ntest  = 10_240
nval   = 10_240

[train]
timeout     = 1e9 #TODO
epochs      = 999_999
batchsize   = 1024 #2048 #3072
kernelrate  = 100 # Train kernel every `kernelrate` iterations
kernelsteps = 10 # Gradient updates per kernel train
GANrate     = 10 # Train GAN losses every `GANrate` iterations, on average
GANsucc     = 10 # Train GAN losses for `GANsucc` successive iterations, then break for `(GANrate-1)*GANsucc` iterations
Dsteps      = 10 # Train GAN losses with `Dsteps` discrim updates per genatr update

[eval]
ninfer      = 128 # Number of MLE parameter inferences
nperms      = 128 # Number of permutations for c_alpha calculation + perm plot
inferperiod = 300.0 # TODO
saveperiod  = 300.0 # TODO
showrate    = 1 # TODO

[opt]
lrdrop   = 1.0 #10.0 3.1623 #1.7783
lrthresh = 1e-5
lrrate   = 1000
[opt.k]
loss = "tstatistic" #"MMD"
lr = 1e-2
[opt.mmd]
lr = 1e-4 #3.1623e-4 #1.0e-5 #TODO
[opt.G]
lr = 1e-4 #3.1623e-4 #1.0e-5 #TODO
[opt.D]
lr = 1e-4 #3.1623e-4 #1.0e-5 #TODO

[arch]
type = "hyb" # "gan", "mmd", or "hyb"
[arch.kernel]
nbandwidth = 4 #TODO
#bwbounds  = [-10.0, 4.0] # bounds for kernel bandwidths (logsigma)
bwbounds   = [-8.0, 4.0] # toy problem bounds for kernel bandwidths (logsigma)
[arch.genatr]
hdim        = 128
nhidden     = 2
#maxcorr    = 0.005 # normalized signals
#noisebounds= [-10.0, -4.0] # normalized signals
#maxcorr    = 0.025 # unnormalized signals (but scaled down by 1e6)
#noisebounds= [-6.0, -3.0] # unnormalized signals (but scaled down by 1e6)
maxcorr     = 0.1 # toy signals
noisebounds = [-8.0, -2.0] # toy signals
[arch.discrim]
hdim    = 128
nhidden = 2
