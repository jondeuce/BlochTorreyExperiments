####
#### Setup
####

using MMDLearning
using BangBang #TODO
using PyCall
pyplot(size=(800,600))
Ignite.init()

# Init python resources
const torch = pyimport("torch")
const wandb = pyimport("wandb")
const ignite = pyimport("ignite")
const logging = pyimport("logging")
py"""
from ignite.contrib.handlers.wandb_logger import *
"""

using MMDLearning: map_dict, sum_dict, sample_mv_normal, split_mean_softplus_std, apply_dim1, pow2, log2œÄ
const Events = ignite.engine.Events

# Parse command line arguments into default settings
const settings = TOML.parse("""
    [data]
        out    = "./output/ignite-cvae-$(MMDLearning.getnow())"
        ntrain = 102_400
        ntest  = 10_240
        nval   = 10_240

    [train]
        timeout     = 1e9 #TODO 10800.0
        epochs      = 1000_000
        batchsize   = 2048 #256 #512 #1024 #4096
        MMDCVAErate = 1   # Train combined MMD+CVAE loss every `MMDCVAErate` epochs
        CVAErate    = 0   # Train CVAE loss every `CVAErate` iterations
        MMDrate     = 0   # Train MMD loss every `MMDrate` epochs
        GANrate     = 0   # Train GAN losses every `GANrate` iterations
        Dsteps      = 5   # Train GAN losses with `Dsteps` discrim updates per genatr update
        # GANcycle    = 1   # CVAE and GAN take turns training for `GANcycle` consecutive epochs (0 trains both each iteration)
        # Dcycle      = 0   # Train for `Dcycle` epochs of discrim only, followed by `Dcycle` epochs of CVAE and GAN together
        # Dheadstart  = 0   # Train discriminator for `Dheadstart` epochs before training generator
        kernelrate  = 0   # Train kernel every `kernelrate` iterations
        kernelsteps = 1   # Gradient updates per kernel train
        [train.augment]
            gradient      = false # Gradient of input signal (1D central difference)
            laplacian     = false # Laplacian of input signal (1D second order)
            encoderspace  = false # Discriminate encoder space representations
            residuals     = false # Discriminate residual vectors
            fftcat        = false # Fourier transform of input signal, concatenating real/imag
            fftsplit      = true  # Fourier transform of input signal, treating real/imag separately
        [train.transform]
            flipsignals   = true  # Randomly reverse signals
            Dchunk        = 112   # Discriminator looks at random chunks of size `Dchunk` (0 uses whole signal)
            # Gsamples      = 1   # Discriminator averages over `Gsamples` instances of corrected signals

    [eval]
        valevalperiod   = 120.0 #TODO 300.0 60.0
        trainevalperiod = 120.0 #TODO 300.0 60.0
        saveperiod      = 300.0 #TODO
        printperiod     = 120.0 #TODO 300.0 60.0

    [opt]
        lrrel    = 0.1 #0.03 # Learning rate relative to batch size, i.e. lr = lrrel / batchsize
        lrthresh = 0.0 #1e-5 # Absolute minimum learning rate
        lrdrop   = 10.0 #3.17 #1.0 # Drop learning rate by factor `lrdrop` every `lrrate` epochs
        lrrate   = 1000_000 # Drop learning rate by factor `lrdrop` every `lrrate` epochs
        [opt.cvae]
            lrrel = "%PARENT%"
        [opt.genatr]
            lrrel = "%PARENT%"
        [opt.discrim]
            lrrel = "%PARENT%"
        [opt.mmd]
            lrrel = "%PARENT%"
            lambda_0        = 1000.0
            lambda_eps      = 10.0 # regularize noise amplitude epsilon
            lambda_deps_dz  = 1.0  # regularize gradient of epsilon w.r.t. latent variables

    [arch]
        physics = "$(get(ENV, "JL_PHYS_MODEL", "toy"))" # "toy" or "mri"
        nlatent = 1 # number of latent variables Z
        zdim    = 8 # embedding dimension of z
        hdim    = 256 # size of hidden layers
        nhidden = 4 # number of hidden layers
        skip    = false # skip connection
        [arch.enc1]
            psize   = 32
            head    = 4
            hdim    = "%PARENT%"
            nhidden = "%PARENT%"
            skip    = "%PARENT%"
        [arch.enc2]
            psize   = 32
            head    = 4
            hdim    = "%PARENT%"
            nhidden = "%PARENT%"
            skip    = "%PARENT%"
        [arch.dec]
            hdim    = "%PARENT%"
            nhidden = "%PARENT%"
            skip    = "%PARENT%"
        [arch.genatr]
            hdim        = 32    #TODO "%PARENT%"
            nhidden     = 4     #TODO "%PARENT%"
            skip        = false #TODO "%PARENT%"
            maxcorr     = $(get(ENV, "JL_PHYS_MODEL", "toy") == "toy" ? 0.1 : 0.025) # correction amplitude
            noisebounds = $(get(ENV, "JL_PHYS_MODEL", "toy") == "toy" ? [-8.0, -2.0] : [-6.0, -3.0]) # noise amplitude
        [arch.discrim]
            dropout = 0.1
            hdim    = 1         #TODO "%PARENT%"
            nhidden = 0         #TODO "%PARENT%"
            skip    = "%PARENT%"
        [arch.kernel]
            nbandwidth  = 32
            channelwise = false
            bwbounds    = $(get(ENV, "JL_PHYS_MODEL", "toy") == "toy" ? [-8.0, 4.0] : [-10.0, 4.0]) # bounds for kernel bandwidths (logsigma)
""")
Ignite.parse_command_line!(settings)

# Init wandb_logger and save settings
wandb_logger = Ignite.init_wandb_logger(settings)
!isnothing(wandb_logger) && (settings["data"]["out"] = wandb.run.dir)
Ignite.save_and_print(settings; outpath = settings["data"]["out"], filename = "settings.toml")

####
#### Models
####

# Initialize generator + discriminator + kernel
function make_models(phys::PhysicsModel{Float32}, models = Dict{String, Any}(), derived = Dict{String, Any}())
    n   = nsignal(phys) # input signal length
    nŒ∏  = ntheta(phys) # number of physics variables
    Œ∏bd = Œ∏bounds(phys)
    k   = settings["arch"]["nlatent"]::Int # number of latent variables Z
    nz  = settings["arch"]["zdim"]::Int # embedding dimension

    # RiceGenType = LatentVectorRicianCorrector{n,k}
    RiceGenType = LatentVectorRicianNoiseCorrector{n,k}
    # RiceGenType = VectorRicianCorrector{n,k}

    function RESCNN(sz::Pair{Int,Int}, Nhid::Int, Dhid::Int, œÉhid = Flux.relu, œÉout = identity; skip = false)
        Flux.Chain(
            x::AbstractMatrix -> reshape(x, sz[1], 1, 1, size(x,2)),
            Flux.Conv((3,1), 1=>Dhid, identity; pad = Flux.SamePad()),
            mapreduce(vcat, 1:Nhid√∑2) do _
                convlayers = [Flux.Conv((3,1), Dhid=>Dhid, œÉhid; pad = Flux.SamePad()) for _ in 1:2]
                skip ? [Flux.SkipConnection(Flux.Chain(convlayers...), +)] : convlayers
            end...,
            Flux.Conv((1,1), Dhid=>1, identity; pad = Flux.SamePad()),
            x::AbstractArray{<:Any,4} -> reshape(x, sz[1], size(x,4)),
            Flux.Dense(sz[1], sz[2], œÉout),
        )
    end

    function TransformerEncoder(; n = 48, psize = 16, head = 8, hdim = 256, nhidden = 2)
        t = Transformers.Stack(
            Transformers.@nntopo(
                X : # Input (n √ó b)
                X => X : # Reshape (1 √ó n √ó b)
                X => pe : # Positional embedding pe (psize √ó n)
                (X, pe) => E : # Add positional embedding (psize √ó n √ó b)
                E => H : # Transformer encoder (psize √ó n √ó b)
                H => H # Flatten output (psize*n √ó b)
            ),
            X -> reshape(X, 1, size(X)...),
            Transformers.Basic.PositionEmbedding(psize, n; trainable = true),
            (X, pe) -> X .+ pe,
            Flux.Chain([Transformers.Basic.Transformer(psize, head, hdim; future = true, act = Flux.relu, pdrop = 0.0) for i = 1:nhidden]...),
            Flux.flatten,
        )
        Flux.fmap(Flux.testmode!, t) # Force dropout layers inactive
    end

    # Rician generator. First `n` elements for `Œ¥X` scaled to (-Œ¥, Œ¥), second `n` elements for `logœµ` scaled to (noisebounds[1], noisebounds[2])
    get!(models, "genatr") do
        hdim = settings["arch"]["genatr"]["hdim"]::Int
        nhidden = settings["arch"]["genatr"]["nhidden"]::Int
        skip = settings["arch"]["genatr"]["skip"]::Bool
        maxcorr = settings["arch"]["genatr"]["maxcorr"]::Float64
        noisebounds = settings["arch"]["genatr"]["noisebounds"]::Vector{Float64}
        nin, nout = ninput(RiceGenType), noutput(RiceGenType)
        OutputScale =
            RiceGenType <: Union{<:VectorRicianCorrector, <:LatentVectorRicianCorrector} ? MMDLearning.CatScale([(-maxcorr, maxcorr), (noisebounds...,)], [n,n]) :
            RiceGenType <: FixedNoiseVectorRicianCorrector ? MMDLearning.CatScale([(-maxcorr, maxcorr)], [n]) :
            RiceGenType <: LatentVectorRicianNoiseCorrector ? MMDLearning.CatScale([(noisebounds...,)], [n]) :
            error("Unsupported corrector type: $RiceGenType")
        Flux.Chain(
            MMDLearning.MLP(nin => nout, nhidden, hdim, Flux.relu, tanh; skip = skip)...,
            OutputScale,
        ) |> to32
        #=
            Flux.Chain(
                Flux.Dense(nin, nout, tanh),
                OutputScale,
            ) |> to32
        =#
    end

    # Wrapped generator produces ùêë^2n outputs parameterizing n Rician distributions
    get!(derived, "ricegen") do; RiceGenType(models["genatr"]) end

    # Encoders
    get!(models, "enc1") do
        hdim = settings["arch"]["enc1"]["hdim"]::Int
        nhidden = settings["arch"]["enc1"]["nhidden"]::Int
        skip = settings["arch"]["enc1"]["skip"]::Bool
        psize = settings["arch"]["enc1"]["psize"]::Int
        head = settings["arch"]["enc1"]["head"]::Int
        MMDLearning.MLP(n => 2*nz, nhidden, hdim, Flux.relu, identity; skip = skip) |> to32
        # RESCNN(n => 2*nz, nhidden, hdim, Flux.relu, identity; skip = skip) |> to32
        # Transformers.Stack(
        #     Transformers.@nntopo( X : X => H : H => Œºr ),
        #     TransformerEncoder(; n, psize, head, hdim, nhidden),
        #     MMDLearning.MLP(psize*n => 2*nz, 0, hdim, Flux.relu, identity),
        # ) |> to32
    end

    get!(models, "enc2") do
        hdim = settings["arch"]["enc2"]["hdim"]::Int
        nhidden = settings["arch"]["enc2"]["nhidden"]::Int
        skip = settings["arch"]["enc2"]["skip"]::Bool
        psize = settings["arch"]["enc2"]["psize"]::Int
        head = settings["arch"]["enc2"]["head"]::Int
        MMDLearning.MLP(n + nŒ∏ + k => 2*nz, nhidden, hdim, Flux.relu, identity; skip = skip) |> to32
        # RESCNN(n + nŒ∏ + k => 2*nz, nhidden, hdim, Flux.relu, identity; skip = skip) |> to32
        # Transformers.Stack(
        #     Transformers.@nntopo( (X,Œ∏,Z) : X => H : (H,Œ∏,Z) => HŒ∏Z : HŒ∏Z => Œºq ),
        #     TransformerEncoder(; n, psize, head, hdim, nhidden),
        #     vcat,
        #     MMDLearning.MLP(psize*n + nŒ∏ + k => 2*nz, 0, hdim, Flux.relu, identity),
        # ) |> to32
    end

    # Decoder
    get!(models, "dec") do
        hdim = settings["arch"]["dec"]["hdim"]::Int
        nhidden = settings["arch"]["dec"]["nhidden"]::Int
        skip = settings["arch"]["dec"]["skip"]::Bool
        Flux.Chain(
            MMDLearning.MLP(n + nz => 2*(nŒ∏ + k), nhidden, hdim, Flux.relu, identity; skip = skip)...,
            # RESCNN(n + nz => 2*(nŒ∏ + k), nhidden, hdim, Flux.relu, identity; skip = skip)...,
            MMDLearning.CatScale(eltype(Œ∏bd)[Œ∏bd; (-1, 1)], [ones(Int, nŒ∏); k + nŒ∏ + k]),
        ) |> to32
    end

    # Discriminator
    get!(models, "discrim") do
        hdim = settings["arch"]["discrim"]["hdim"]::Int
        nhidden = settings["arch"]["discrim"]["nhidden"]::Int
        skip = settings["arch"]["discrim"]["skip"]::Bool
        dropout = settings["arch"]["discrim"]["dropout"]::Float64 |> p -> p > 0 ? eltype(phys)(p) : nothing
        Dchunk = settings["train"]["transform"]["Dchunk"]::Int
        augsizes = Dict{String,Int}(["gradient" => n-2, "laplacian" => n-2, "encoderspace" => nz, "residuals" => n, "fftcat" => 2*(n√∑2 + 1), "fftsplit" => 2*(n√∑2 + 1)])
        nin = min(n, Dchunk) + sum((s -> ifelse(settings["train"]["augment"][s]::Bool, min(augsizes[s], Dchunk), 0)).(keys(augsizes)))
        MMDLearning.MLP(nin => 1, nhidden, hdim, Flux.relu, Flux.sigmoid; skip = skip, dropout = dropout) |> to32
        # RESCNN(n => 1, nhidden, hdim, Flux.relu, Flux.sigmoid; skip = skip) |> to32
    end

    # MMD kernel bandwidths
    get!(models, "logsigma") do
        bwbounds = settings["arch"]["kernel"]["bwbounds"]::Vector{Float64}
        nbandwidth = settings["arch"]["kernel"]["nbandwidth"]::Int
        channelwise = settings["arch"]["kernel"]["channelwise"]::Bool
        range(bwbounds...; length = nbandwidth+2)[2:end-1] |> logœÉ -> (channelwise ? repeat(logœÉ, 1, n) : logœÉ) |> to32
    end

    # MMD kernel wrapper
    get!(derived, "kernel") do; MMDLearning.ExponentialKernel(models["logsigma"]) end

    # Misc. useful operators
    get!(derived, "gradient") do; MMDLearning.CentralDifference() |> to32 end
    get!(derived, "laplacian") do; MMDLearning.Laplacian() |> to32 end
    get!(derived, "encoderspace") do; NotTrainable(MMDLearning.flattenchain(Flux.Chain(models["enc1"], split_mean_softplus_std, sample_mv_normal))) end # non-trainable sampling of encoder signal representations

    return models, derived
end

const phys = initialize!(
    MMDLearning.ToyCosineModel{Float32,true}();
    ntrain = settings["data"]["ntrain"]::Int,
    ntest = settings["data"]["ntest"]::Int,
    nval = settings["data"]["nval"]::Int,
)
const models, derived = make_models(phys)
# const models, derived = make_models(phys, map_dict(to32, deepcopy(BSON.load("/home/jdoucette/Documents/code/wandb/tmp/output/ignite-cvae-2020-10-24-T-15-48-22-393/current-models.bson")["models"])))
const optimizers = Dict{String,Any}(
    "cvae"    => Flux.ADAM(settings["opt"]["cvae"]["lrrel"]    / settings["train"]["batchsize"]),
    "genatr"  => Flux.ADAM(settings["opt"]["genatr"]["lrrel"]  / settings["train"]["batchsize"]),
    "discrim" => Flux.ADAM(settings["opt"]["discrim"]["lrrel"] / settings["train"]["batchsize"]),
    "mmd"     => Flux.ADAM(settings["opt"]["mmd"]["lrrel"]     / settings["train"]["batchsize"]),
)
MMDLearning.model_summary(models, joinpath(settings["data"]["out"], "model-summary.txt"))

####
#### Sampling
####

@inline split_theta_latent(Œ∏Z::AbstractMatrix) = size(Œ∏Z,1) == ntheta(phys) ? (Œ∏Z, similar(Œ∏Z,0,size(Œ∏Z,2))) : (Œ∏Z[1:ntheta(phys),:], Œ∏Z[ntheta(phys)+1:end,:])
@inline sampleŒ∏prior_similar(Y, n = size(Y,2)) = rand_similar(Y, ntheta(phys), n) .* (todevice(Œ∏upper(phys)) .- todevice(Œ∏lower(phys))) .+ todevice(Œ∏lower(phys)) #TODO

function InvertY(Y)
    Œºr = models["enc1"](Y)
    Œºr0, œÉr = split_mean_softplus_std(Œºr)
    zr = sample_mv_normal(Œºr0, œÉr)

    Œºx = models["dec"](vcat(Y,zr))
    Œºx0, œÉx = split_mean_softplus_std(Œºx)
    x = sample_mv_normal(Œºx0, œÉx)

    Œ∏, Z = split_theta_latent(x)
    Œ∏ = clamp.(Œ∏, todevice(Œ∏lower(phys)), todevice(Œ∏upper(phys)))
    return Œ∏, Z
end

function sampleŒ∏Z(Y; recover_Œ∏ = true, recover_Z = true)
    nŒ∏, nz = ntheta(phys)::Int, settings["arch"]["nlatent"]::Int
    Œ∏prior() = sampleŒ∏prior_similar(Y, size(Y,2))
    Zprior() = randn_similar(Y, nz, size(Y,2))
    if recover_Œ∏ || recover_Z
        Œ∏hat, Zhat = InvertY(Y)
        Œ∏ = recover_Œ∏ ? Œ∏hat : Œ∏prior()
        Z = recover_Z ? Zhat : Zprior()
        Œ∏, Z
    else
        Œ∏prior(), Zprior()
    end
end

function sampleXŒ∏Z(Y; kwargs...)
    @timeit "sampleŒ∏Z"     Œ∏, Z = sampleŒ∏Z(Y; kwargs...)
    @timeit "signal_model" X = signal_model(phys, Œ∏)
    return X, Œ∏, Z
end

function sampleXÃÇŒ∏Z(Y; kwargs...)
    @timeit "sampleXŒ∏Z" X, Œ∏, Z = sampleXŒ∏Z(Y; kwargs...)
    @timeit "sampleXÃÇ"   XÃÇ = sampleXÃÇ(X, Z)
    return XÃÇ, Œ∏, Z
end

sampleXÃÇ(Y; kwargs...) = sampleXÃÇŒ∏Z(Y; kwargs...)[1]
sampleXÃÇ(X, Z) = corrected_signal_instance(derived["ricegen"], X, Z)

####
#### Augmentations
####

function augmentations(X::AbstractMatrix, XÃÑ::Union{Nothing,<:AbstractMatrix})
    ‚àáX   = settings["train"]["augment"]["gradient"]::Bool ? derived["gradient"](X) : nothing # Signal gradient
    ‚àá¬≤X  = settings["train"]["augment"]["laplacian"]::Bool ? derived["laplacian"](X) : nothing # Signal laplacian
    Xres = settings["train"]["augment"]["residuals"]::Bool && !isnothing(XÃÑ) ? X .- XÃÑ : nothing # Residual relative to different sample XÃÑ = X(Œ∏), Œ∏ ~ P(Œ∏|Y)
    Xenc = settings["train"]["augment"]["encoderspace"]::Bool ? derived["encoderspace"](X) : nothing # Encoder-space signal
    Xfft = settings["train"]["augment"]["fftcat"]::Bool ? vcat(reim(rfft(X,1))...) : nothing # Concatenated real/imag fourier components
    Xrfft, Xifft = settings["train"]["augment"]["fftsplit"]::Bool ? reim(rfft(X,1)) : (nothing, nothing) # Separate real/imag fourier components

    ks = (:signal, :grad, :lap, :res, :enc, :fft, :rfft, :ifft)
    Xs = [X, ‚àáX, ‚àá¬≤X, Xres, Xenc, Xfft, Xrfft, Xifft]
    is = (!isnothing).(Xs)
    Xs = NamedTuple{ks[is]}(Xs[is])

    return Xs
end

function transformations(X::AbstractMatrix)
    Dchunk = settings["train"]["transform"]["Dchunk"]::Int
    flipsignals = settings["train"]["transform"]["flipsignals"]::Bool
    !(0 < Dchunk < size(X,1) || flipsignals) && return X
    i = ifelse(!(0 < Dchunk < size(X,1)), firstindex(X,1):lastindex(X,1), rand(firstindex(X,1):lastindex(X,1)-Dchunk+1) .+ (0:Dchunk-1))
    i = ifelse(!flipsignals, i, ifelse(rand(Bool), i, reverse(i)))
    return X[i,:]
end
transformations(X::AbstractTensor3D) = apply_dim1(transformations, X)

####
#### GANs
####

#= TODO
function GAN_augmentations(X,Z,XÃÑ)
    Gsamples = settings["train"]["transform"]["Gsamples"]::Int
    ŒΩ, œµ = rician_params(derived["ricegen"], X, Z)
    return add_noise_instance(derived["ricegen"], ŒΩ, œµ, Gsamples)
end
=#
GAN_augmentations(X::AbstractMatrix, XÃÑ::Union{Nothing,<:AbstractMatrix}) = mapreduce(transformations, vcat, augmentations(X, XÃÑ))
D_G_X_prob(X,Z,XÃÑ) = apply_dim1(models["discrim"], GAN_augmentations(sampleXÃÇ(X, Z), XÃÑ)) # discrim on genatr data
D_Y_prob(Y,XÃÑ) = apply_dim1(models["discrim"], GAN_augmentations(Y,XÃÑ)) # discrim on real data
Dloss(X,Y,Z,XÃÑ) = (œµ = sqrt(eps(eltype(X))); -sum(log.(D_Y_prob(Y,XÃÑ) .+ œµ) .+ log.(1 .- D_G_X_prob(X,Z,XÃÑ) .+ œµ)) / size(Y,2))
Gloss(X,Z,XÃÑ) = (œµ = sqrt(eps(eltype(X))); sum(log.(1 .- D_G_X_prob(X,Z,XÃÑ) .+ œµ)) / size(Y,2))

####
#### MMD
####

function noiselevel_regularization(œµ::AbstractMatrix)
    ‚àá¬≤œµ = derived["laplacian"](œµ)
    return ‚àö(sum(abs2, ‚àá¬≤œµ) / length(‚àá¬≤œµ))
end

function noiselevel_gradient_regularization(œµ::AbstractMatrix, Z::AbstractMatrix)
    Œîœµ = derived["gradient"](permutedims(œµ, (2,1))) # (b-2) √ó n Differences
    ŒîZ = derived["gradient"](permutedims(Z, (2,1))) # (b-2) √ó nz Differences
    ŒîZ¬≤ = sum(abs2, ŒîZ; dims = 2) ./ size(ŒîZ, 2) # (b-2) √ó 1 Mean squared distance
    ŒîZ0¬≤ = eltype(Z)(1e-3)
    dœµ_dZ = @. Œîœµ^2 / (ŒîZ¬≤ + ŒîZ0¬≤)
    return ‚àö(sum(dœµ_dZ) / length(dœµ_dZ))
end

# Maximum mean discrepency (m*MMD^2) loss
MMDloss(XÃÇ,Y) = size(Y,2) * mmd(derived["kernel"], XÃÇ, Y)
function MMDlosses(Y)
    # Sample Œ∏,Z from CVAE posterior, differentiating only through generator corrections `sampleXÃÇ`
    X, Œ∏, Z = Zygote.@ignore sampleXŒ∏Z(Y; recover_Œ∏ = true, recover_Z = true)
    ŒΩ, œµ = rician_params(derived["ricegen"], X, Z)
    XÃÇ = add_noise_instance(derived["ricegen"], ŒΩ, œµ)

    XÃÇs = augmentations(XÃÇ, nothing)
    Ys = augmentations(Y, nothing)
    ‚Ñì  = map(MMDloss, XÃÇs, Ys)

    Œª_œµ = eltype(Y)(settings["opt"]["mmd"]["lambda_eps"]::Float64)
    if Œª_œµ > 0
        R = Œª_œµ * noiselevel_regularization(œµ)
        ‚Ñì = push!!(‚Ñì, :reg_eps => R)
    end

    Œª_‚àÇœµ‚àÇZ = eltype(Y)(settings["opt"]["mmd"]["lambda_deps_dz"]::Float64)
    if Œª_‚àÇœµ‚àÇZ > 0
        R = Œª_‚àÇœµ‚àÇZ * noiselevel_gradient_regularization(œµ, Z)
        ‚Ñì = push!!(‚Ñì, :reg_Z => R)
    end

    return ‚Ñì
end

####
#### CVAE
####

KLDivUnitNormal(Œº, œÉ) = (sum(@. pow2(œÉ) + pow2(Œº) - 2 * log(œÉ)) - length(Œº)) / (2 * size(Œº,2)) # KL-divergence between approximation posterior and N(0, 1) prior (Note: sum over dim=1, mean over dim=2)
KLDivergence(Œºq0, œÉq, Œºr0, œÉr) = (sum(@. pow2(œÉq / œÉr) + pow2((Œºr0 - Œºq0) / œÉr) - 2 * log(œÉq / œÉr)) - length(Œºq0)) / (2 * size(Œºq0,2)) # KL-divergence contribution to cross-entropy (Note: sum over dim=1, mean over dim=2)
EvidenceLowerBound(x, Œºx0, œÉx) = (sum(@. pow2((x - Œºx0) / œÉx) + 2 * log(œÉx)) + length(Œºx0) * log2œÄ(eltype(Œºx0))) / (2 * size(Œºx0,2)) # Negative log-likelihood/ELBO contribution to cross-entropy (Note: sum over dim=1, mean over dim=2)
DataConsistency(Y, ŒºG0, œÉG; dims = :) = -sum(MMDLearning._rician_logpdf_cuda.(Y, ŒºG0, œÉG); dims) # Rician negative log likelihood

# Conditional variational autoencoder losses
function CVAElosses(Y; recover_Z = true)
    # Sample Œ∏,Z from priors, differentiating through generator corrections on the encoder 2 side only
    X, Œ∏, Z = Zygote.@ignore sampleXŒ∏Z(Y; recover_Œ∏ = false, recover_Z = false) # sample Œ∏ and Z priors
    XÃÇ = sampleXÃÇ(X, Z)

    # Cross-entropy loss function
    Œºr0, œÉr = split_mean_softplus_std(models["enc1"](Zygote.dropgrad(XÃÇ))) # Drop gradient so that encoder 1 can't cheat
    Œºr0, œÉr = split_mean_softplus_std(models["enc1"](XÃÇ))
    Œºq0, œÉq = split_mean_softplus_std(models["enc2"](vcat(XÃÇ,Œ∏,Z)))
    zq = sample_mv_normal(Œºq0, œÉq)
    Œºx0, œÉx  = split_mean_softplus_std(models["dec"](vcat(XÃÇ,zq)))
    ŒºŒ∏0, ŒºZ0 = split_theta_latent(Œºx0)
    œÉŒ∏,  œÉZ  = split_theta_latent(œÉx)

    KLdiv = KLDivergence(Œºq0, œÉq, Œºr0, œÉr)
    ELBO = if recover_Z
        EvidenceLowerBound(vcat(Œ∏,Z), Œºx0, œÉx)
    else
        EvidenceLowerBound(Œ∏, ŒºŒ∏0, œÉŒ∏)
    end
    ‚Ñì = (; KLdiv, ELBO)

    return ‚Ñì
end

####
#### MAP
####

function MAP(Y; miniter = 1, maxiter = 100, alpha = 0.05, verbose = false)
    function MAPsample!(ŒºŒ∏ = nothing, i = 1)
        if isnothing(ŒºŒ∏)
            ŒºŒ∏, Z = sampleŒ∏Z(Y; recover_Œ∏ = true, recover_Z = true)
        else
            Œ∏, Z = sampleŒ∏Z(Y; recover_Œ∏ = true, recover_Z = true)
            T = eltype(Y)
            ŒºŒ∏ .= T(1/i) .* Œ∏ .+ T((i-1)/i) .* ŒºŒ∏
        end
        X = signal_model(phys, ŒºŒ∏)
        ŒΩ, œµ = rician_params(derived["ricegen"], X, Z)
        ‚Ñì = DataConsistency(Y, ŒΩ, œµ; dims = 1)
        return (; ‚Ñì, X, ŒºŒ∏, Z)
    end
    function MAPinner()
        @unpack ‚Ñì, ŒºŒ∏ = MAPsample!()
        n = length(‚Ñì)
        Œºlast, œÉlast = mean_and_std(‚Ñì)
        verbose && @info 1, Œºlast, œÉlast
        for i in 2:maxiter
            ‚Ñì .= min.(‚Ñì, MAPsample!(ŒºŒ∏, i).‚Ñì)
            Œº, œÉ = mean_and_std(‚Ñì)
            verbose && @info i, Œº, œÉ
            (i >= miniter) && (Œºlast - Œº < alpha * œÉ / ‚àön) && break
            Œºlast, œÉlast = Œº, œÉ
        end
        return ‚Ñì
    end
    MAPinner()
end

####
#### Training
####

# Global state
const cb_state = Dict{String,Any}()
const logger = DataFrame(
    :epoch      => Int[], # mandatory field
    :iter       => Int[], # mandatory field
    :dataset    => Symbol[], # mandatory field
    :time       => Union{Float64, Missing}[],
)

make_data_tuples(dataset) = tuple.(copy.(eachcol(sampleY(phys, :all; dataset = dataset))))
train_loader = torch.utils.data.DataLoader(make_data_tuples(:train); batch_size = settings["train"]["batchsize"], shuffle = true, drop_last = true)
val_loader = torch.utils.data.DataLoader(make_data_tuples(:val); batch_size = settings["train"]["batchsize"], shuffle = false, drop_last = true) #Note: drop_last=true and batch_size=train_batchsize for MMD (else, batch_size = settings["data"]["nval"] is fine)

function train_step(engine, batch)
    Ytrain_cpu, = Ignite.array.(batch)
    Ytrain = Ytrain_cpu |> todevice
    outputs = Dict{Any,Any}()

    @timeit "train batch" CUDA.@sync begin
        every(rate) = rate <= 0 ? false : mod(engine.state.iteration-1, rate) == 0
        train_MMDCVAE = every(settings["train"]["MMDCVAErate"]::Int)
        train_CVAE = every(settings["train"]["CVAErate"]::Int)
        train_MMD = every(settings["train"]["MMDrate"]::Int)
        train_GAN = train_discrim = train_genatr = every(settings["train"]["GANrate"]::Int)
        train_k = every(settings["train"]["kernelrate"]::Int)

        # Train Self MMD CVAE loss
        train_MMDCVAE && @timeit "mmd + cvae" CUDA.@sync let
            ps = Flux.params(models["genatr"], models["enc1"], models["enc2"], models["dec"])
            Œª_0 = eltype(Ytrain)(settings["opt"]["mmd"]["lambda_0"]::Float64)
            @timeit "forward" CUDA.@sync ‚Ñì, back = Zygote.pullback(ps) do
                mmd = sum(MMDlosses(Ytrain))
                cvae = sum(CVAElosses(Ytrain; recover_Z = true))
                return Œª_0 * mmd + cvae
            end
            @timeit "reverse" CUDA.@sync gs = back(one(eltype(phys)))
            @timeit "update!" CUDA.@sync Flux.Optimise.update!(optimizers["mmd"], ps, gs)
            outputs["loss"] = ‚Ñì
        end

        # Train CVAE loss
        train_CVAE && @timeit "cvae" CUDA.@sync let
            ps = Flux.params(models["enc1"], models["enc2"], models["dec"])
            @timeit "forward"   CUDA.@sync ‚Ñì, back = Zygote.pullback(() -> sum(CVAElosses(Ytrain; recover_Z = true)), ps)
            @timeit "reverse"   CUDA.@sync gs = back(one(eltype(phys)))
            @timeit "update!"   CUDA.@sync Flux.Optimise.update!(optimizers["cvae"], ps, gs)
            outputs["CVAE"] = ‚Ñì
        end

        # Train MMD loss
        train_MMD && @timeit "mmd" CUDA.@sync let
            @timeit "genatr" CUDA.@sync let
                ps = Flux.params(models["genatr"])
                @timeit "forward" CUDA.@sync ‚Ñì, back = Zygote.pullback(() -> sum(MMDlosses(Ytrain)), ps)
                @timeit "reverse" CUDA.@sync gs = back(one(eltype(phys)))
                @timeit "update!" CUDA.@sync Flux.Optimise.update!(optimizers["mmd"], ps, gs)
                outputs["MMD"] = ‚Ñì
            end
        end

        # Train GAN loss
        train_GAN && @timeit "gan" CUDA.@sync let
            @timeit "sampleXŒ∏Z" CUDA.@sync Xtrain, Œ∏train, Ztrain = sampleXŒ∏Z(Ytrain; recover_Œ∏ = true, recover_Z = true)
            @timeit "sampleXÃÇ"   CUDA.@sync XÃÑtrain = nothing #TODO
            train_discrim && @timeit "discrim" CUDA.@sync let
                ps = Flux.params(models["discrim"])
                for _ in 1:settings["train"]["Dsteps"]
                    @timeit "forward" CUDA.@sync ‚Ñì, back = Zygote.pullback(() -> Dloss(Xtrain, Ytrain, Ztrain, XÃÑtrain), ps)
                    @timeit "reverse" CUDA.@sync gs = back(one(eltype(phys)))
                    @timeit "update!" CUDA.@sync Flux.Optimise.update!(optimizers["discrim"], ps, gs)
                    outputs["Dloss"] = ‚Ñì
                end
            end
            train_genatr && @timeit "genatr" CUDA.@sync let
                ps = Flux.params(models["genatr"])
                @timeit "forward" CUDA.@sync ‚Ñì, back = Zygote.pullback(() -> Gloss(Xtrain, Ztrain, XÃÑtrain), ps)
                @timeit "reverse" CUDA.@sync gs = back(one(eltype(phys)))
                @timeit "update!" CUDA.@sync Flux.Optimise.update!(optimizers["genatr"], ps, gs)
                outputs["Gloss"] = ‚Ñì
            end
        end

        # Train MMD kernel bandwidths
        train_k && @timeit "kernel" CUDA.@sync let
            @timeit "sample G(X)" XÃÇtrain = sampleXÃÇ(Ytrain; recover_Œ∏ = true, recover_Z = true)
            for _ in 1:settings["train"]["kernelsteps"]
                success = train_kernel_bandwidth_flux!(
                    models["logsigma"], XÃÇtrain, Ytrain;
                    kernelloss = settings["opt"]["kernel"]["loss"],
                    kernellr = settings["opt"]["kernel"]["lr"],
                    bwbounds = settings["arch"]["kernel"]["bwbounds"]) # timed internally
                !success && break
            end
        end

        # # CVAE and GAN take turns training for `GANcycle` consecutive epochs
        # GANcycle = settings["train"]["GANcycle"]::Int
        # train_CVAE = (GANcycle == 0) || iseven(div(engine.state.epoch-1, GANcycle))
        # train_GAN  = (GANcycle == 0) || !train_CVAE
        # train_discrim = true
        # train_genatr = true

        # # `Dcycle` epochs of discrim only, followed by `Dcycle` epochs of CVAE and GAN together
        # Dcycle = settings["train"]["Dcycle"]::Int
        # if Dcycle != 0 && iseven(div(engine.state.epoch-1, Dcycle))
        #     train_CVAE = false
        #     train_GAN  = true
        #     train_discrim = true
        #     train_genatr = false
        # else
        #     # Train CVAE every iteration, GAN every `GANrate` iterations
        #     train_CVAE = true
        #     train_GAN  = mod(engine.state.iteration-1, settings["train"]["GANrate"]::Int) == 0
        #     train_discrim = true
        #     # train_genatr = true
        #     train_genatr = engine.state.epoch >= settings["train"]["Dheadstart"]::Int
        # end
    end

    return deepcopy(outputs)
end

function compute_metrics(engine, batch; dataset)
    @timeit "compute metrics" CUDA.@sync begin
        # Update callback state
        cb_state["last_time"] = get!(cb_state, "curr_time", time())
        cb_state["curr_time"] = time()
        cb_state["metrics"] = Dict{String,Any}()

        # Initialize output metrics dictionary
        log_metrics = Dict{Symbol,Any}()
        log_metrics[:epoch]   = trainer.state.epoch
        log_metrics[:iter]    = trainer.state.iteration
        log_metrics[:dataset] = dataset
        log_metrics[:time]    = cb_state["curr_time"] - cb_state["last_time"]

        # Invert Y and make Xs
        Y, = Ignite.array.(batch) .|> todevice
        Nbatch = size(Y,2)
        Œ∏, Z = InvertY(Y)
        X = signal_model(phys, Œ∏)
        Œ¥G0, œÉG = correction_and_noiselevel(derived["ricegen"], X, Z)
        ŒºG0 = add_correction(derived["ricegen"], X, Œ¥G0)
        XÃÇ = add_noise_instance(derived["ricegen"], ŒºG0, œÉG)

        let
            ‚Ñì_CVAE = CVAElosses(Y; recover_Z = true)
            ‚Ñì_CVAE = push!!(‚Ñì_CVAE, :CVAE => sum(‚Ñì_CVAE))
            merge!!(log_metrics, ‚Ñì_CVAE)

            ‚Ñì_MMD = MMDlosses(Y)
            ‚Ñì_MMD = NamedTuple{Symbol.(:MMD_, keys(‚Ñì_MMD))}(values(‚Ñì_MMD)) # prefix labels with "MMD_"
            ‚Ñì_MMD = push!!(‚Ñì_MMD, :MMD => sum(‚Ñì_MMD))
            merge!!(log_metrics, ‚Ñì_MMD)

            Œª_0 = eltype(Y)(settings["opt"]["mmd"]["lambda_0"]::Float64)
            loss = ‚Ñì_CVAE.CVAE + Œª_0 * ‚Ñì_MMD.MMD
            Zreg = sum(abs2, Z) / (2*Nbatch)
            @pack! log_metrics = loss, Zreg

            if settings["train"]["GANrate"]::Int > 0
                œµ = sqrt(eps(eltype(X)))
                XÃÑnew = nothing #TODO
                d_y = D_Y_prob(Y, XÃÑnew)
                d_g_x = D_G_X_prob(X, Z, XÃÑnew)
                Dloss = -mean(log.(d_y .+ œµ) .+ log.(1 .- d_g_x .+ œµ))
                Gloss = mean(log.(1 .- d_g_x .+ œµ))
                D_Y   = mean(d_y)
                D_G_X = mean(d_g_x)
            else
                Gloss = Dloss = D_Y = D_G_X = missing
            end
            @pack! log_metrics = Gloss, Dloss, D_Y, D_G_X
        end

        # Cache cb state variables using naming convention
        function cache_cb_state!(Y, Œ∏, Z, XŒ∏, Œ¥Œ∏, œµŒ∏, XŒ∏Œ¥, XŒ∏hat, YŒ∏, YŒ∏hat; suf::String)
            cb_state["Y"     * suf] = Y     |> Flux.cpu
            cb_state["Œ∏"     * suf] = Œ∏     |> Flux.cpu
            cb_state["Z"     * suf] = Z     |> Flux.cpu
            cb_state["XŒ∏"    * suf] = XŒ∏    |> Flux.cpu
            cb_state["Œ¥Œ∏"    * suf] = Œ¥Œ∏    |> Flux.cpu
            cb_state["œµŒ∏"    * suf] = œµŒ∏    |> Flux.cpu
            cb_state["XŒ∏Œ¥"   * suf] = XŒ∏Œ¥   |> Flux.cpu
            cb_state["XŒ∏hat" * suf] = XŒ∏hat |> Flux.cpu
            cb_state["YŒ∏"    * suf] = YŒ∏    |> Flux.cpu
            cb_state["YŒ∏hat" * suf] = YŒ∏hat |> Flux.cpu
            return cb_state
        end

        # Cache values for evaluating CVAE performance for recovering Y
        let
            YŒ∏ = hasclosedform(phys) ? signal_model(ClosedForm(phys), Œ∏) : missing
            YŒ∏hat = hasclosedform(phys) ? signal_model(ClosedForm(phys), Œ∏, noiselevel(ClosedForm(phys), Œ∏, Z)) : missing
            cache_cb_state!(Y, Œ∏, Z, X, Œ¥G0, œÉG, ŒºG0, XÃÇ, YŒ∏, YŒ∏hat; suf = "")

            all_Yhat_rmse = sqrt.(mean(abs2, Y .- XÃÇ; dims = 1)) |> Flux.cpu |> vec
            all_Yhat_logL = MAP(Y) |> Flux.cpu |> vec #TODO DataConsistency(Y, ŒºG0, œÉG; dims = 1) |> Flux.cpu |> vec
            Yhat_rmse = mean(all_Yhat_rmse)
            Yhat_logL = mean(all_Yhat_logL)
            @pack! cb_state["metrics"] = all_Yhat_rmse, all_Yhat_logL
            @pack! log_metrics = Yhat_rmse, Yhat_logL
        end

        # Cache values for evaluating CVAE performance for estimating parameters of XÃÇ
        let
            Œ∏fit, Zfit = sampleŒ∏Z(XÃÇ; recover_Œ∏ = true, recover_Z = true)
            XŒ∏fit = signal_model(phys, Œ∏fit)
            Œ¥Œ∏fit, œµŒ∏fit = correction_and_noiselevel(derived["ricegen"], XŒ∏fit, Zfit)
            XŒ∏Œ¥fit = add_correction(derived["ricegen"], XŒ∏fit, Œ¥Œ∏fit)
            XŒ∏hatfit = add_noise_instance(derived["ricegen"], XŒ∏Œ¥fit, œµŒ∏fit)
            YŒ∏fit = hasclosedform(phys) ? signal_model(ClosedForm(phys), Œ∏fit) : missing
            YŒ∏hatfit = hasclosedform(phys) ? signal_model(ClosedForm(phys), Œ∏fit, noiselevel(ClosedForm(phys), Œ∏fit, Zfit)) : missing
            cache_cb_state!(XÃÇ, Œ∏fit, Zfit, XŒ∏fit, Œ¥Œ∏fit, œµŒ∏fit, XŒ∏Œ¥fit, XŒ∏hatfit, YŒ∏fit, YŒ∏hatfit; suf = "fit") #TODO XÃÇ or Y?

            rmse = hasclosedform(phys) ? sqrt(mean(abs2, YŒ∏fit - XŒ∏Œ¥fit)) : missing
            all_Xhat_rmse = sqrt.(mean(abs2, XÃÇ .- XŒ∏hatfit; dims = 1)) |> Flux.cpu |> vec
            all_Xhat_logL = MAP(XÃÇ) |> Flux.cpu |> vec #TODO DataConsistency(XÃÇ, XŒ∏Œ¥fit, œµŒ∏fit; dims = 1) |> Flux.cpu |> vec
            Xhat_rmse = mean(all_Xhat_rmse)
            Xhat_logL = mean(all_Xhat_logL)
            theta_err = 100 .* mean(abs, (Œ∏ .- Œ∏fit) ./ (todevice(Œ∏upper(phys)) .- todevice(Œ∏lower(phys))); dims = 2) |> Flux.cpu |> vec |> copy
            Z_err = mean(abs, Z .- Zfit; dims = 2) |> Flux.cpu |> vec |> copy
            @pack! cb_state["metrics"] = all_Xhat_rmse, all_Xhat_logL
            @pack! log_metrics = Xhat_rmse, Xhat_logL, theta_err, Z_err, rmse
        end

        # Update logger dataframe
        is_consecutive = !isempty(logger) && (logger.epoch[end] == log_metrics[:epoch] && logger.iter[end] == log_metrics[:iter] && logger.dataset[end] === log_metrics[:dataset])
        nbatches = div(settings["data"]["n$dataset"]::Int, settings["train"]["batchsize"]::Int)
        !is_consecutive ? push!(logger, log_metrics; cols = :union) : (logger.time[end] += log_metrics[:time])
        for (k,v) in log_metrics
            if k ‚àâ [:epoch, :iter, :dataset, :time]
                !is_consecutive ? (logger[end, k] /= nbatches) : (logger[end, k] += v / nbatches)
            end
        end

        # Return metrics for logging
        output_metrics = Dict{Any,Any}(string(k) => deepcopy(v) for (k,v) in log_metrics if k ‚àâ [:epoch, :iter, :dataset, :time]) # output non-housekeeping metrics
        merge!(cb_state["metrics"], output_metrics) # merge all log metrics into cb_state
        filter!(((k,v),) -> !ismissing(v), output_metrics) # return non-missing metrics (wandb cannot handle missing)

        return output_metrics
    end
end

function makeplots(;showplot = false)
    function plot_epsilon(; knots = (-5.0, 5.0), seriestype = :line, showplot = false)
        function plot_epsilon_inner(; start, stop, zlen = 256, levels = 50)
            n, nŒ∏, nz = nsignal(phys)::Int, ntheta(phys)::Int, settings["arch"]["nlatent"]::Int
            Y = sampleY(phys, zlen * nz; dataset = :train) |> to32
            Œ∏ = sampleŒ∏prior_similar(Y, zlen * nz)
            X = signal_model(phys, Œ∏)
            Z = repeat(randn_similar(Y, nz, 1), 1, zlen, nz)
            for i in 1:nz
                Z[i,:,i] .= range(start, stop; length = zlen)
            end
            œµ = rician_params(derived["ricegen"], X, reshape(Z, nz, :))[2] |> œµ -> reshape(œµ, :, zlen, nz)
            Y, Œ∏, X, Z, œµ = Flux.cpu.((Y, Œ∏, X, Z, œµ))
            ps = map(1:nz) do i
                zlabs = nz == 1 ? "" : latexstring(" (" * join(map(j -> L"$Z_%$(j)$ = %$(round(Z[1,1,j]; digits = 2))", setdiff(1:nz, i)), ", ") * ")")
                kwcommon = (; leg = :none, colorbar = :right, color = cgrad(:cividis), xlabel = L"$t$", title = L"$\epsilon$ vs. $t$ and $Z_{%$(i)}$%$(zlabs)")
                if seriestype === :surface
                    surface(reshape(1:n,n,1), Z[i,:,i]', œµ[:,:,i]; ylabel = L"$Z_{%$(i)}$", fill_z = œµ[:,:,i], camera = (60.0, 30.0), kwcommon...)
                elseif seriestype === :contour
                    contourf(repeat(1:n,1,zlen), repeat(Z[i,:,i]',n,1), œµ[:,:,i]; ylabel = L"$Z_{%$(i)}$", levels, kwcommon...)
                else
                    plot(œµ[:,:,i]; line_z = Z[i,:,i]', ylabel = L"$\epsilon$", lw = 2, alpha = 0.3, kwcommon...)
                end
            end
            return ps
        end
        ps = mapreduce(vcat, 1:length(knots)-1; init = Any[]) do i
            plot_epsilon_inner(; start = knots[i], stop = knots[i+1])
        end
        p = plot(ps...)
        if showplot; display(p); end
        return p
    end

    try
        Dict{Symbol, Any}(
            :ricemodel   => MMDLearning.plot_rician_model(logger, cb_state, phys; showplot = showplot, bandwidths = haskey(models, "logsigma") ? (permutedims(models["logsigma"]) |> Flux.cpu) : nothing),
            :signals     => MMDLearning.plot_rician_signals(logger, cb_state, phys; showplot = showplot),
            :vaesignals  => MMDLearning.plot_vae_rician_signals(logger, cb_state, phys; showplot = showplot),
            :infer       => MMDLearning.plot_rician_inference(logger, cb_state, phys; showplot = showplot),
            :ganloss     => MMDLearning.plot_gan_loss(logger, cb_state, phys; showplot = showplot, lrdroprate = settings["opt"]["lrrate"], lrdrop = settings["opt"]["lrdrop"]),
            :vallosses   => MMDLearning.plot_all_logger_losses(logger, cb_state, phys; dataset = :val, showplot = showplot),
            :trainlosses => MMDLearning.plot_all_logger_losses(logger, cb_state, phys; dataset = :train, showplot = showplot),
            :epsline     => plot_epsilon(; showplot = showplot, seriestype = :line), #TODO
            :epscontour  => plot_epsilon(; showplot = showplot, seriestype = :contour), #TODO
        )
    catch e
        handleinterrupt(e; msg = "Error plotting")
    end
end

trainer = ignite.engine.Engine(@j2p train_step)
trainer.logger = ignite.utils.setup_logger("trainer")

val_evaluator = ignite.engine.Engine(@j2p (args...) -> compute_metrics(args...; dataset = :val))
val_evaluator.logger = ignite.utils.setup_logger("val_evaluator")

train_evaluator = ignite.engine.Engine(@j2p (args...) -> compute_metrics(args...; dataset = :train))
train_evaluator.logger = ignite.utils.setup_logger("train_evaluator")

# Force terminate
trainer.add_event_handler(
    Events.STARTED | Events.ITERATION_STARTED | Events.ITERATION_COMPLETED,
    @j2p Ignite.terminate_file_event(file = joinpath(settings["data"]["out"], "stop"))
)

# Timeout
trainer.add_event_handler(
    Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.timeout_event_filter(settings["train"]["timeout"])),
    @j2p function (engine)
        @info "Exiting: training time exceeded $(DECAES.pretty_time(settings["train"]["timeout"]))"
        engine.terminate()
    end
)

# Compute callback metrics
trainer.add_event_handler(
    Events.STARTED | Events.TERMINATE | Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.throttler_event_filter(settings["eval"]["valevalperiod"])),
    @j2p (engine) -> val_evaluator.run(val_loader)
)
trainer.add_event_handler(
    Events.STARTED | Events.TERMINATE | Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.throttler_event_filter(settings["eval"]["trainevalperiod"])),
    @j2p (engine) -> train_evaluator.run(train_loader)
)

# Checkpoint current model + logger + make plots
trainer.add_event_handler(
    Events.STARTED | Events.TERMINATE | Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.throttler_event_filter(settings["eval"]["saveperiod"])),
    @j2p function (engine)
        @timeit "checkpoint" let models = map_dict(Flux.cpu, models)
            @timeit "save current model" saveprogress(@dict(models, logger); savefolder = settings["data"]["out"], prefix = "current-")
            @timeit "make current plots" plothandles = makeplots()
            @timeit "save current plots" saveplots(plothandles; savefolder = settings["data"]["out"], prefix = "current-")
        end
    end
)

# Check for + save best model + logger + make plots
trainer.add_event_handler(
    Events.TERMINATE | Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.throttler_event_filter(settings["eval"]["saveperiod"])),
    @j2p function (engine)
        losses = logger.Yhat_logL[logger.dataset .=== :val] |> skipmissing |> collect
        if !isempty(losses) && (length(losses) == 1 || losses[end] < minimum(losses[1:end-1]))
            @timeit "save best progress" let models = map_dict(Flux.cpu, models)
                @timeit "save best model" saveprogress(@dict(models, logger); savefolder = settings["data"]["out"], prefix = "best-")
                @timeit "make best plots" plothandles = makeplots()
                @timeit "save best plots" saveplots(plothandles; savefolder = settings["data"]["out"], prefix = "best-")
            end
        end
    end
)

# Drop learning rate
trainer.add_event_handler(
    Events.EPOCH_COMPLETED,
    @j2p Ignite.droplr_file_event(optimizers;
        file = joinpath(settings["data"]["out"], "droplr"),
        lrrate = settings["opt"]["lrrate"]::Int,
        lrdrop = settings["opt"]["lrdrop"]::Float64,
        lrthresh = settings["opt"]["lrthresh"]::Float64,
    )
)

# Print TimerOutputs timings
trainer.add_event_handler(
    Events.TERMINATE | Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.throttler_event_filter(settings["eval"]["printperiod"])),
    @j2p function (engine)
        show(stdout, TimerOutputs.get_defaulttimer()); println("\n")
        show(stdout, last(logger[!,[names(logger)[1:4]; sort(names(logger)[5:end])]], 10)); println("\n")
        (engine.state.epoch == 1) && TimerOutputs.reset_timer!() # throw out compilation timings
    end
)

####
#### Weights & biases logger
####

# Attach training/validation output handlers
if !isnothing(wandb_logger)
    for (tag, engine, event) in [
            ("step",  trainer,         Events.EPOCH_COMPLETED(event_filter = @j2p Ignite.timeout_event_filter(settings["eval"]["trainevalperiod"]))), # computed each iteration; throttle recording
            ("train", train_evaluator, Events.EPOCH_COMPLETED), # throttled above; record every epoch
            ("val",   val_evaluator,   Events.EPOCH_COMPLETED), # throttled above; record every epoch
        ]
        wandb_logger.attach_output_handler(engine;
            tag = tag,
            event_name = event,
            output_transform = @j2p(metrics -> metrics),
            global_step_transform = @j2p((args...; kwargs...) -> trainer.state.epoch),
        )
    end
end

####
#### Run trainer
####

TimerOutputs.reset_timer!()
trainer.run(train_loader, settings["train"]["epochs"])
